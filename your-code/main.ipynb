{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla=soup.find_all('article', class_='Box-row d-flex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Emil Ernerfeldt'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code\n",
    "#primero de la lista\n",
    "tabla[0]('a')[2].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'egui'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#segundo de la lista\n",
    "tabla[0]('a')[4].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Emil Ernerfeldt (egui)',\n",
       " 'Earle F. Philhower, III (arduino-pico)',\n",
       " 'Nikita Sobolev (awesome-cryptography)',\n",
       " 'Stephen Celis (SQLite.swift)',\n",
       " 'Justin Fagnani (mixwith.js)',\n",
       " 'Manu MA (qwik-conference-app)',\n",
       " 'Joshua (Follow)',\n",
       " 'Simon H (Follow)',\n",
       " 'Marcus Olsson (obsidian-projects)',\n",
       " 'Ben V. Brown (IronOS)',\n",
       " 'Jonny Borges (getx)',\n",
       " 'Andrew Kane (the-ultimate-guide-to-ruby-timeouts)',\n",
       " 'Wangchong Zhou (xeHentai)',\n",
       " 'Mislav Marohnić (will_paginate)',\n",
       " 'Matthias Fey (pytorch_scatter)',\n",
       " 'Elliana May (duckdb-extension-framework)',\n",
       " 'Romain Beaumont (img2dataset)',\n",
       " 'Hari Sekhon (DevOps-Bash-tools)',\n",
       " 'osy (Follow)',\n",
       " 'Adam Johnson (django-upgrade)',\n",
       " 'Pedro Cuenca (alzheimer)',\n",
       " 'Alex Gaynor (what-happens-when)',\n",
       " 'Henrik Rydgård (ppsspp)',\n",
       " 'Joshua Levy (the-art-of-command-line)',\n",
       " 'Mu Li (autocut)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for i in range(len(tabla)):\n",
    "    name = tabla[i]('a')[2].text.strip()\n",
    "    username = tabla[i]('a')[4].text.strip()\n",
    "    lst.append(name + ' ' + '(' + username + ')')\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "tabla=soup.find_all('article', class_='Box-row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Star'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla[16]('a')[1].text.strip().replace('\\n', '').replace('/', '').replace('       ', '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bregman-ariedevops-exercises',\n",
       " 'public-apispublic-apis',\n",
       " 'geohottinygrad',\n",
       " 'mlflowmlflow',\n",
       " 'PaddlePaddlePaddleDetection',\n",
       " 'googlejax',\n",
       " 'iterativvNostalgiaForInfinity',\n",
       " 'netbox-communitynetbox',\n",
       " 'tiangolotyper',\n",
       " 'streamlitstreamlit',\n",
       " 'modelscopemodelscope',\n",
       " 'LetusDevopsLearnPython',\n",
       " 'nerfstudio-projectnerfstudio',\n",
       " 'idanyaalgo-trader',\n",
       " 'heartexlabslabelImg',\n",
       " 'microsoftpyright',\n",
       " 'sqlmapprojectsqlmap',\n",
       " 'unifyaiivy',\n",
       " 'cryticslither',\n",
       " 'ultralyticsyolov5',\n",
       " 'home-assistantcore',\n",
       " 'WeAreMahsaAminiFreeInternet',\n",
       " 'open-mmlabmmocr',\n",
       " 'Lightning-AIlightning',\n",
       " 'demistocontent']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for i in range(len(tabla)):\n",
    "    if tabla[i]('a')[1].text.strip().replace('\\n', '').replace('/', '').replace(' ', '') == 'Star':\n",
    "        lst.append(tabla[i]('a')[2].text.strip().replace('\\n', '').replace('/', '').replace(' ', ''))\n",
    "    else:\n",
    "        lst.append(tabla[i]('a')[1].text.strip().replace('\\n', '').replace('/', '').replace(' ', ''))\n",
    "    \n",
    "\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla=soup.find_all('img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla[2]['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8c/Extended-protection-shackle.svg/20px-Extended-protection-shackle.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/d/df/Walt_Disney_1946.JPG/220px-Walt_Disney_1946.JPG',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/87/Walt_Disney_1942_signature.svg/150px-Walt_Disney_1942_signature.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg/220px-Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Walt_Disney_envelope_ca._1921.jpg/220px-Walt_Disney_envelope_ca._1921.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Trolley_Troubles_poster.jpg/170px-Trolley_Troubles_poster.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/4/4e/Steamboat-willie.jpg/170px-Steamboat-willie.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/5/57/Walt_Disney_1935.jpg/170px-Walt_Disney_1935.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg/220px-Walt_Disney_Snow_white_1937_trailer_screenshot_%2813%29.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/15/Disney_drawing_goofy.jpg/170px-Disney_drawing_goofy.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/WaltDisneyplansDisneylandDec1954.jpg/220px-WaltDisneyplansDisneylandDec1954.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Walt_disney_portrait_right.jpg/170px-Walt_disney_portrait_right.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Walt_Disney_Grave.JPG/170px-Walt_Disney_Grave.JPG',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Roy_O._Disney_with_Company_at_Press_Conference.jpg/170px-Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/13/DisneySchiphol1951.jpg/220px-DisneySchiphol1951.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Disney1968.jpg/170px-Disney1968.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Disney_Oscar_1953_%28cropped%29.jpg/170px-Disney_Oscar_1953_%28cropped%29.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/30px-Commons-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/38px-Wikisource-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/34px-Wikiquote-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Disneyland_Resort_logo.svg/135px-Disneyland_Resort_logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/d/da/Animation_disc.svg/20px-Animation_disc.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/6/69/P_vip.svg/19px-P_vip.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Magic_Kingdom_castle.jpg/15px-Magic_Kingdom_castle.jpg',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/e/e7/Video-x-generic.svg/19px-Video-x-generic.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Flag_of_Los_Angeles_County%2C_California.svg/21px-Flag_of_Los_Angeles_County%2C_California.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Blank_television_set.svg/21px-Blank_television_set.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/a/a4/Flag_of_the_United_States.svg/21px-Flag_of_the_United_States.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/4/4a/Commons-logo.svg/14px-Commons-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Wikiquote-logo.svg/16px-Wikiquote-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Wikisource-logo.svg/18px-Wikisource-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Wikidata-logo.svg/21px-Wikidata-logo.svg.png',\n",
       " '//upload.wikimedia.org/wikipedia/en/thumb/8/8a/OOjs_UI_icon_edit-ltr-progressive.svg/10px-OOjs_UI_icon_edit-ltr-progressive.svg.png',\n",
       " '//en.wikipedia.org/wiki/Special:CentralAutoLogin/start?type=1x1',\n",
       " '/static/images/footer/wikimedia-button.png',\n",
       " '/static/images/footer/poweredby_mediawiki_88x31.png']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for i in range(len(tabla)):\n",
    "    lst.append(tabla[i]['src'])\n",
    "    \n",
    "\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "url ='https://en.wikipedia.org/wiki/Python_(mythology)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = soup.find_all('a')#[3]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wiki/Pythia'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla[3]['href']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/Pythia',\n",
       " '/wiki/Python_(disambiguation)',\n",
       " '/wiki/File:Apollo_dan_Pithon.jpg',\n",
       " '/wiki/File:Apollo_dan_Pithon.jpg',\n",
       " '/wiki/Apollo',\n",
       " '/wiki/Virgil_Solis',\n",
       " '/wiki/Ovid',\n",
       " '/wiki/Metamorphoses',\n",
       " '/wiki/Greek_mythology',\n",
       " '/wiki/Greek_language']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst=[]\n",
    "for i in range(len(tabla)):\n",
    "    try:\n",
    "        if 'wiki' in tabla[i]['href']:\n",
    "            lst.append(tabla[i]['href'])\n",
    "    except:\n",
    "        None\n",
    "        \n",
    "lst[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('div', class_='usctitlechanged'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code \n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = soup.find_all('h3', class_='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OMAR ALEXANDER CARDENAS'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla[0]('a')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OMAR ALEXANDER CARDENAS',\n",
       " 'ALEXIS FLORES',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ',\n",
       " 'YULAN ADONAY ARCHAGA CARIAS',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'MICHAEL JAMES PRATT',\n",
       " 'RUJA IGNATOVA',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'RAFAEL CARO-QUINTERO']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for i in range(len(tabla)):\n",
    "    lst.append(tabla[i]('a')[0].text)\n",
    "\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = soup.find_all('tbody', id = 'tbody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2022-11-08 16:40:58.1'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#date_time\n",
    "tabla[0]('tr')[0]('td')[3]('a')[0].text.replace('\\xa0', ' ').replace('   ', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'19.45'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#latitud\n",
    "tabla[0]('tr')[0]('td')[4].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'155.61'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#longitud\n",
    "tabla[0]('tr')[0]('td')[6].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ISLAND OF HAWAII, HAWAII'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#region name\n",
    "tabla[0]('tr')[0]('td')[11].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date_time': '2022-11-08 16:40:58.1',\n",
       "  'latitude': '19.45',\n",
       "  'longitude': '155.61',\n",
       "  'region': 'ISLAND OF HAWAII, HAWAII'},\n",
       " {'date_time': '2022-11-08 16:40:43.0',\n",
       "  'latitude': '32.96',\n",
       "  'longitude': '70.28',\n",
       "  'region': 'VALPARAISO, CHILE'},\n",
       " {'date_time': '2022-11-08 16:35:24.8',\n",
       "  'latitude': '39.60',\n",
       "  'longitude': '120.40',\n",
       "  'region': 'NORTHERN CALIFORNIA'},\n",
       " {'date_time': '2022-11-08 16:19:42.3',\n",
       "  'latitude': '36.00',\n",
       "  'longitude': '118.38',\n",
       "  'region': 'CENTRAL CALIFORNIA'},\n",
       " {'date_time': '2022-11-08 16:11:35.0',\n",
       "  'latitude': '29.62',\n",
       "  'longitude': '80.54',\n",
       "  'region': 'NEPAL-INDIA BORDER REGION'},\n",
       " {'date_time': '2022-11-08 16:04:03.7',\n",
       "  'latitude': '28.61',\n",
       "  'longitude': '17.88',\n",
       "  'region': 'CANARY ISLANDS, SPAIN REGION'},\n",
       " {'date_time': '2022-11-08 16:00:22.0',\n",
       "  'latitude': '9.49',\n",
       "  'longitude': '79.59',\n",
       "  'region': 'PANAMA'},\n",
       " {'date_time': '2022-11-08 15:49:16.0',\n",
       "  'latitude': '18.03',\n",
       "  'longitude': '66.86',\n",
       "  'region': 'PUERTO RICO'},\n",
       " {'date_time': '2022-11-08 15:38:00.0',\n",
       "  'latitude': '46.06',\n",
       "  'longitude': '14.05',\n",
       "  'region': 'SLOVENIA'},\n",
       " {'date_time': '2022-11-08 15:32:57.6',\n",
       "  'latitude': '46.97',\n",
       "  'longitude': '9.77',\n",
       "  'region': 'SWITZERLAND'},\n",
       " {'date_time': '2022-11-08 15:27:12.0',\n",
       "  'latitude': '24.10',\n",
       "  'longitude': '67.30',\n",
       "  'region': 'SALTA, ARGENTINA'},\n",
       " {'date_time': '2022-11-08 15:26:07.0',\n",
       "  'latitude': '39.50',\n",
       "  'longitude': '123.16',\n",
       "  'region': 'NORTHERN CALIFORNIA'},\n",
       " {'date_time': '2022-11-08 15:23:24.2',\n",
       "  'latitude': '43.62',\n",
       "  'longitude': '9.01',\n",
       "  'region': 'LIGURIAN SEA'},\n",
       " {'date_time': '2022-11-08 15:22:36.9',\n",
       "  'latitude': '29.33',\n",
       "  'longitude': '81.17',\n",
       "  'region': 'NEPAL'},\n",
       " {'date_time': '2022-11-08 15:17:23.9',\n",
       "  'latitude': '18.01',\n",
       "  'longitude': '66.87',\n",
       "  'region': 'PUERTO RICO'},\n",
       " {'date_time': '2022-11-08 15:08:26.8',\n",
       "  'latitude': '19.55',\n",
       "  'longitude': '156.10',\n",
       "  'region': 'HAWAII REGION, HAWAII'},\n",
       " {'date_time': '2022-11-08 14:50:48.0',\n",
       "  'latitude': '2.83',\n",
       "  'longitude': '129.77',\n",
       "  'region': 'SERAM, INDONESIA'},\n",
       " {'date_time': '2022-11-08 14:49:11.0',\n",
       "  'latitude': '22.26',\n",
       "  'longitude': '68.73',\n",
       "  'region': 'ANTOFAGASTA, CHILE'},\n",
       " {'date_time': '2022-11-08 14:43:44.8',\n",
       "  'latitude': '39.16',\n",
       "  'longitude': '0.30',\n",
       "  'region': 'SPAIN'},\n",
       " {'date_time': '2022-11-08 14:38:45.6',\n",
       "  'latitude': '52.39',\n",
       "  'longitude': '179.41',\n",
       "  'region': 'ANDREANOF ISLANDS, ALEUTIAN IS.'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for i in range(20):\n",
    "    \n",
    "    date_time = (tabla[0]('tr')[i]('td')[3]('a')[0].text.replace('\\xa0', ' ').replace('   ', ' '))\n",
    "    latitude = (tabla[0]('tr')[i]('td')[4].text.strip())\n",
    "    longitude = (tabla[0]('tr')[i]('td')[6].text.strip())\n",
    "    region_name = (tabla[0]('tr')[i]('td')[11].text.strip())\n",
    "    \n",
    "    lst.append({'date_time': date_time,\n",
    "               'latitude': latitude,\n",
    "               'longitude': longitude,\n",
    "               'region': region_name})\n",
    "\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-08 16:40:58.1</td>\n",
       "      <td>19.45</td>\n",
       "      <td>155.61</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-08 16:40:43.0</td>\n",
       "      <td>32.96</td>\n",
       "      <td>70.28</td>\n",
       "      <td>VALPARAISO, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-08 16:35:24.8</td>\n",
       "      <td>39.60</td>\n",
       "      <td>120.40</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-08 16:19:42.3</td>\n",
       "      <td>36.00</td>\n",
       "      <td>118.38</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-08 16:11:35.0</td>\n",
       "      <td>29.62</td>\n",
       "      <td>80.54</td>\n",
       "      <td>NEPAL-INDIA BORDER REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-11-08 16:04:03.7</td>\n",
       "      <td>28.61</td>\n",
       "      <td>17.88</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-11-08 16:00:22.0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>79.59</td>\n",
       "      <td>PANAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-11-08 15:49:16.0</td>\n",
       "      <td>18.03</td>\n",
       "      <td>66.86</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-11-08 15:38:00.0</td>\n",
       "      <td>46.06</td>\n",
       "      <td>14.05</td>\n",
       "      <td>SLOVENIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-11-08 15:32:57.6</td>\n",
       "      <td>46.97</td>\n",
       "      <td>9.77</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-11-08 15:27:12.0</td>\n",
       "      <td>24.10</td>\n",
       "      <td>67.30</td>\n",
       "      <td>SALTA, ARGENTINA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-11-08 15:26:07.0</td>\n",
       "      <td>39.50</td>\n",
       "      <td>123.16</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-11-08 15:23:24.2</td>\n",
       "      <td>43.62</td>\n",
       "      <td>9.01</td>\n",
       "      <td>LIGURIAN SEA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-11-08 15:22:36.9</td>\n",
       "      <td>29.33</td>\n",
       "      <td>81.17</td>\n",
       "      <td>NEPAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-11-08 15:17:23.9</td>\n",
       "      <td>18.01</td>\n",
       "      <td>66.87</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-11-08 15:08:26.8</td>\n",
       "      <td>19.55</td>\n",
       "      <td>156.10</td>\n",
       "      <td>HAWAII REGION, HAWAII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-11-08 14:50:48.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>129.77</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-11-08 14:49:11.0</td>\n",
       "      <td>22.26</td>\n",
       "      <td>68.73</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-11-08 14:43:44.8</td>\n",
       "      <td>39.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>SPAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-11-08 14:38:45.6</td>\n",
       "      <td>52.39</td>\n",
       "      <td>179.41</td>\n",
       "      <td>ANDREANOF ISLANDS, ALEUTIAN IS.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time latitude longitude                           region\n",
       "0   2022-11-08 16:40:58.1    19.45    155.61         ISLAND OF HAWAII, HAWAII\n",
       "1   2022-11-08 16:40:43.0    32.96     70.28                VALPARAISO, CHILE\n",
       "2   2022-11-08 16:35:24.8    39.60    120.40              NORTHERN CALIFORNIA\n",
       "3   2022-11-08 16:19:42.3    36.00    118.38               CENTRAL CALIFORNIA\n",
       "4   2022-11-08 16:11:35.0    29.62     80.54        NEPAL-INDIA BORDER REGION\n",
       "5   2022-11-08 16:04:03.7    28.61     17.88     CANARY ISLANDS, SPAIN REGION\n",
       "6   2022-11-08 16:00:22.0     9.49     79.59                           PANAMA\n",
       "7   2022-11-08 15:49:16.0    18.03     66.86                      PUERTO RICO\n",
       "8   2022-11-08 15:38:00.0    46.06     14.05                         SLOVENIA\n",
       "9   2022-11-08 15:32:57.6    46.97      9.77                      SWITZERLAND\n",
       "10  2022-11-08 15:27:12.0    24.10     67.30                 SALTA, ARGENTINA\n",
       "11  2022-11-08 15:26:07.0    39.50    123.16              NORTHERN CALIFORNIA\n",
       "12  2022-11-08 15:23:24.2    43.62      9.01                     LIGURIAN SEA\n",
       "13  2022-11-08 15:22:36.9    29.33     81.17                            NEPAL\n",
       "14  2022-11-08 15:17:23.9    18.01     66.87                      PUERTO RICO\n",
       "15  2022-11-08 15:08:26.8    19.55    156.10            HAWAII REGION, HAWAII\n",
       "16  2022-11-08 14:50:48.0     2.83    129.77                 SERAM, INDONESIA\n",
       "17  2022-11-08 14:49:11.0    22.26     68.73               ANTOFAGASTA, CHILE\n",
       "18  2022-11-08 14:43:44.8    39.16      0.30                            SPAIN\n",
       "19  2022-11-08 14:38:45.6    52.39    179.41  ANDREANOF ISLANDS, ALEUTIAN IS."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(lst)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar(string):\n",
    "    \n",
    "    try:\n",
    "        return string.split(' ')\n",
    "    except:\n",
    "        return [np.nan, np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst=[]\n",
    "\n",
    "for e in df.date_time:\n",
    "    lst.append(limpiar(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['date', 'time']]=lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_time</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-11-08 16:40:58.1</td>\n",
       "      <td>19.45</td>\n",
       "      <td>155.61</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:40:58.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-11-08 16:40:43.0</td>\n",
       "      <td>32.96</td>\n",
       "      <td>70.28</td>\n",
       "      <td>VALPARAISO, CHILE</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:40:43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-11-08 16:35:24.8</td>\n",
       "      <td>39.60</td>\n",
       "      <td>120.40</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:35:24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-11-08 16:19:42.3</td>\n",
       "      <td>36.00</td>\n",
       "      <td>118.38</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:19:42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-11-08 16:11:35.0</td>\n",
       "      <td>29.62</td>\n",
       "      <td>80.54</td>\n",
       "      <td>NEPAL-INDIA BORDER REGION</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:11:35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-11-08 16:04:03.7</td>\n",
       "      <td>28.61</td>\n",
       "      <td>17.88</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:04:03.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-11-08 16:00:22.0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>79.59</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:00:22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-11-08 15:49:16.0</td>\n",
       "      <td>18.03</td>\n",
       "      <td>66.86</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:49:16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-11-08 15:38:00.0</td>\n",
       "      <td>46.06</td>\n",
       "      <td>14.05</td>\n",
       "      <td>SLOVENIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:38:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-11-08 15:32:57.6</td>\n",
       "      <td>46.97</td>\n",
       "      <td>9.77</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:32:57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-11-08 15:27:12.0</td>\n",
       "      <td>24.10</td>\n",
       "      <td>67.30</td>\n",
       "      <td>SALTA, ARGENTINA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:27:12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022-11-08 15:26:07.0</td>\n",
       "      <td>39.50</td>\n",
       "      <td>123.16</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:26:07.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022-11-08 15:23:24.2</td>\n",
       "      <td>43.62</td>\n",
       "      <td>9.01</td>\n",
       "      <td>LIGURIAN SEA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:23:24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022-11-08 15:22:36.9</td>\n",
       "      <td>29.33</td>\n",
       "      <td>81.17</td>\n",
       "      <td>NEPAL</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:22:36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022-11-08 15:17:23.9</td>\n",
       "      <td>18.01</td>\n",
       "      <td>66.87</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:17:23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022-11-08 15:08:26.8</td>\n",
       "      <td>19.55</td>\n",
       "      <td>156.10</td>\n",
       "      <td>HAWAII REGION, HAWAII</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:08:26.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-11-08 14:50:48.0</td>\n",
       "      <td>2.83</td>\n",
       "      <td>129.77</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>14:50:48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-11-08 14:49:11.0</td>\n",
       "      <td>22.26</td>\n",
       "      <td>68.73</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>14:49:11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-11-08 14:43:44.8</td>\n",
       "      <td>39.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>14:43:44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-11-08 14:38:45.6</td>\n",
       "      <td>52.39</td>\n",
       "      <td>179.41</td>\n",
       "      <td>ANDREANOF ISLANDS, ALEUTIAN IS.</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>14:38:45.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                date_time latitude longitude                           region  \\\n",
       "0   2022-11-08 16:40:58.1    19.45    155.61         ISLAND OF HAWAII, HAWAII   \n",
       "1   2022-11-08 16:40:43.0    32.96     70.28                VALPARAISO, CHILE   \n",
       "2   2022-11-08 16:35:24.8    39.60    120.40              NORTHERN CALIFORNIA   \n",
       "3   2022-11-08 16:19:42.3    36.00    118.38               CENTRAL CALIFORNIA   \n",
       "4   2022-11-08 16:11:35.0    29.62     80.54        NEPAL-INDIA BORDER REGION   \n",
       "5   2022-11-08 16:04:03.7    28.61     17.88     CANARY ISLANDS, SPAIN REGION   \n",
       "6   2022-11-08 16:00:22.0     9.49     79.59                           PANAMA   \n",
       "7   2022-11-08 15:49:16.0    18.03     66.86                      PUERTO RICO   \n",
       "8   2022-11-08 15:38:00.0    46.06     14.05                         SLOVENIA   \n",
       "9   2022-11-08 15:32:57.6    46.97      9.77                      SWITZERLAND   \n",
       "10  2022-11-08 15:27:12.0    24.10     67.30                 SALTA, ARGENTINA   \n",
       "11  2022-11-08 15:26:07.0    39.50    123.16              NORTHERN CALIFORNIA   \n",
       "12  2022-11-08 15:23:24.2    43.62      9.01                     LIGURIAN SEA   \n",
       "13  2022-11-08 15:22:36.9    29.33     81.17                            NEPAL   \n",
       "14  2022-11-08 15:17:23.9    18.01     66.87                      PUERTO RICO   \n",
       "15  2022-11-08 15:08:26.8    19.55    156.10            HAWAII REGION, HAWAII   \n",
       "16  2022-11-08 14:50:48.0     2.83    129.77                 SERAM, INDONESIA   \n",
       "17  2022-11-08 14:49:11.0    22.26     68.73               ANTOFAGASTA, CHILE   \n",
       "18  2022-11-08 14:43:44.8    39.16      0.30                            SPAIN   \n",
       "19  2022-11-08 14:38:45.6    52.39    179.41  ANDREANOF ISLANDS, ALEUTIAN IS.   \n",
       "\n",
       "          date        time  \n",
       "0   2022-11-08  16:40:58.1  \n",
       "1   2022-11-08  16:40:43.0  \n",
       "2   2022-11-08  16:35:24.8  \n",
       "3   2022-11-08  16:19:42.3  \n",
       "4   2022-11-08  16:11:35.0  \n",
       "5   2022-11-08  16:04:03.7  \n",
       "6   2022-11-08  16:00:22.0  \n",
       "7   2022-11-08  15:49:16.0  \n",
       "8   2022-11-08  15:38:00.0  \n",
       "9   2022-11-08  15:32:57.6  \n",
       "10  2022-11-08  15:27:12.0  \n",
       "11  2022-11-08  15:26:07.0  \n",
       "12  2022-11-08  15:23:24.2  \n",
       "13  2022-11-08  15:22:36.9  \n",
       "14  2022-11-08  15:17:23.9  \n",
       "15  2022-11-08  15:08:26.8  \n",
       "16  2022-11-08  14:50:48.0  \n",
       "17  2022-11-08  14:49:11.0  \n",
       "18  2022-11-08  14:43:44.8  \n",
       "19  2022-11-08  14:38:45.6  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.45</td>\n",
       "      <td>155.61</td>\n",
       "      <td>ISLAND OF HAWAII, HAWAII</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:40:58.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.96</td>\n",
       "      <td>70.28</td>\n",
       "      <td>VALPARAISO, CHILE</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:40:43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.60</td>\n",
       "      <td>120.40</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:35:24.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.00</td>\n",
       "      <td>118.38</td>\n",
       "      <td>CENTRAL CALIFORNIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:19:42.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.62</td>\n",
       "      <td>80.54</td>\n",
       "      <td>NEPAL-INDIA BORDER REGION</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:11:35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>28.61</td>\n",
       "      <td>17.88</td>\n",
       "      <td>CANARY ISLANDS, SPAIN REGION</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:04:03.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.49</td>\n",
       "      <td>79.59</td>\n",
       "      <td>PANAMA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>16:00:22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>18.03</td>\n",
       "      <td>66.86</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:49:16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>46.06</td>\n",
       "      <td>14.05</td>\n",
       "      <td>SLOVENIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:38:00.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>46.97</td>\n",
       "      <td>9.77</td>\n",
       "      <td>SWITZERLAND</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:32:57.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.10</td>\n",
       "      <td>67.30</td>\n",
       "      <td>SALTA, ARGENTINA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:27:12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>39.50</td>\n",
       "      <td>123.16</td>\n",
       "      <td>NORTHERN CALIFORNIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:26:07.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>43.62</td>\n",
       "      <td>9.01</td>\n",
       "      <td>LIGURIAN SEA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:23:24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>29.33</td>\n",
       "      <td>81.17</td>\n",
       "      <td>NEPAL</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:22:36.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.01</td>\n",
       "      <td>66.87</td>\n",
       "      <td>PUERTO RICO</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:17:23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>19.55</td>\n",
       "      <td>156.10</td>\n",
       "      <td>HAWAII REGION, HAWAII</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>15:08:26.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.83</td>\n",
       "      <td>129.77</td>\n",
       "      <td>SERAM, INDONESIA</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>14:50:48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>22.26</td>\n",
       "      <td>68.73</td>\n",
       "      <td>ANTOFAGASTA, CHILE</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>14:49:11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39.16</td>\n",
       "      <td>0.30</td>\n",
       "      <td>SPAIN</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>14:43:44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>52.39</td>\n",
       "      <td>179.41</td>\n",
       "      <td>ANDREANOF ISLANDS, ALEUTIAN IS.</td>\n",
       "      <td>2022-11-08</td>\n",
       "      <td>14:38:45.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   latitude longitude                           region        date        time\n",
       "0     19.45    155.61         ISLAND OF HAWAII, HAWAII  2022-11-08  16:40:58.1\n",
       "1     32.96     70.28                VALPARAISO, CHILE  2022-11-08  16:40:43.0\n",
       "2     39.60    120.40              NORTHERN CALIFORNIA  2022-11-08  16:35:24.8\n",
       "3     36.00    118.38               CENTRAL CALIFORNIA  2022-11-08  16:19:42.3\n",
       "4     29.62     80.54        NEPAL-INDIA BORDER REGION  2022-11-08  16:11:35.0\n",
       "5     28.61     17.88     CANARY ISLANDS, SPAIN REGION  2022-11-08  16:04:03.7\n",
       "6      9.49     79.59                           PANAMA  2022-11-08  16:00:22.0\n",
       "7     18.03     66.86                      PUERTO RICO  2022-11-08  15:49:16.0\n",
       "8     46.06     14.05                         SLOVENIA  2022-11-08  15:38:00.0\n",
       "9     46.97      9.77                      SWITZERLAND  2022-11-08  15:32:57.6\n",
       "10    24.10     67.30                 SALTA, ARGENTINA  2022-11-08  15:27:12.0\n",
       "11    39.50    123.16              NORTHERN CALIFORNIA  2022-11-08  15:26:07.0\n",
       "12    43.62      9.01                     LIGURIAN SEA  2022-11-08  15:23:24.2\n",
       "13    29.33     81.17                            NEPAL  2022-11-08  15:22:36.9\n",
       "14    18.01     66.87                      PUERTO RICO  2022-11-08  15:17:23.9\n",
       "15    19.55    156.10            HAWAII REGION, HAWAII  2022-11-08  15:08:26.8\n",
       "16     2.83    129.77                 SERAM, INDONESIA  2022-11-08  14:50:48.0\n",
       "17    22.26     68.73               ANTOFAGASTA, CHILE  2022-11-08  14:49:11.0\n",
       "18    39.16      0.30                            SPAIN  2022-11-08  14:43:44.8\n",
       "19    52.39    179.41  ANDREANOF ISLANDS, ALEUTIAN IS.  2022-11-08  14:38:45.6"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns='date_time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = soup.find_all('a', class_='link-box')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'æ\\x97¥æ\\x9c¬èª\\x9e'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#language name\n",
    "tabla[1].text.split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6458000+ articles'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of related articles\n",
    "tabla[0]('small')[0].text.replace('\\xa0', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'language_name': 'English',\n",
       "  'number of related articles': '6458000+ articles'},\n",
       " {'language_name': 'æ\\x97¥æ\\x9c¬èª\\x9e',\n",
       "  'number of related articles': '1314000+ è¨\\x98äº\\x8b'},\n",
       " {'language_name': 'EspaÃ±ol',\n",
       "  'number of related articles': '1755000+ artÃ\\xadculos'},\n",
       " {'language_name': 'Ð',\n",
       "  'number of related articles': '1798000+ Ñ\\x81Ñ\\x82Ð°Ñ\\x82ÐµÐ¹'},\n",
       " {'language_name': 'FranÃ§ais',\n",
       "  'number of related articles': '2400000+ articles'},\n",
       " {'language_name': 'Deutsch',\n",
       "  'number of related articles': '2667000+ Artikel'},\n",
       " {'language_name': 'Italiano', 'number of related articles': '1742000+ voci'},\n",
       " {'language_name': 'ä¸\\xadæ\\x96\\x87',\n",
       "  'number of related articles': '1256000+ æ\\x9d¡ç\\x9b® / æ¢\\x9dç\\x9b®'},\n",
       " {'language_name': 'PortuguÃªs',\n",
       "  'number of related articles': '1085000+ artigos'},\n",
       " {'language_name': 'Ø§Ù\\x84Ø¹Ø±Ø¨Ù\\x8aØ©',\n",
       "  'number of related articles': '1159000+ Ù\\x85Ù\\x82Ø§Ù\\x84Ø©'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for i in range(len(tabla)):\n",
    "    language = tabla[i].text.split()[0]\n",
    "    number = tabla[i]('small')[0].text.replace('\\xa0', '')\n",
    "    \n",
    "    lst.append({'language_name': language,\n",
    "               'number of related articles': number})\n",
    "    \n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code \n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla=soup.find_all('a', class_='govuk-link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Crime and justice'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabla[5].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = []\n",
    "for i in range(4, len(tabla)):\n",
    "    lst.append(tabla[i].text)\n",
    "lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = soup.find_all('tbody')[0]('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mandarin Chinese(incl. Standard Chinese, but excl. other varieties)'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#language\n",
    "tabla[0].text.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'920'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of native speakers\n",
    "tabla[1].text.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mandarin Chinese(incl. Standard Chinese, but excl. other varieties)',\n",
       " 'Spanish',\n",
       " 'English',\n",
       " 'Hindi(excl. Urdu)',\n",
       " 'Bengali',\n",
       " 'Portuguese',\n",
       " 'Russian',\n",
       " 'Japanese',\n",
       " 'Yue Chinese(incl. Cantonese)',\n",
       " 'Vietnamese']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1 = []\n",
    "for i in range(0, 37, 4):\n",
    "    lst1.append(tabla[i].text.replace('\\n', ''))\n",
    "    \n",
    "lst2 = []\n",
    "for i in range(1, 38, 4):\n",
    "    lst2.append(tabla[1].text.replace('\\n', ''))\n",
    "\n",
    "lst1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['920', '920', '920', '920', '920', '920', '920', '920', '920', '920']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['language']= lst1\n",
    "df['number_of_native_speaker']= lst2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>number_of_native_speaker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mandarin Chinese(incl. Standard Chinese, but e...</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spanish</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hindi(excl. Urdu)</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bengali</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Portuguese</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Russian</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Japanese</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Yue Chinese(incl. Cantonese)</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Vietnamese</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            language number_of_native_speaker\n",
       "0  Mandarin Chinese(incl. Standard Chinese, but e...                      920\n",
       "1                                            Spanish                      920\n",
       "2                                            English                      920\n",
       "3                                  Hindi(excl. Urdu)                      920\n",
       "4                                            Bengali                      920\n",
       "5                                         Portuguese                      920\n",
       "6                                            Russian                      920\n",
       "7                                           Japanese                      920\n",
       "8                       Yue Chinese(incl. Cantonese)                      920\n",
       "9                                         Vietnamese                      920"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla=soup.find_all('tbody', class_ = 'lister-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cadena perpetua'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#movie name (empezando en 1 saltos de 2)\n",
    "tabla[0]('a')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2008'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initial release (empezando en 5 saltos de 7)\n",
    "tabla[0]('span')[5].text.replace('(', '').replace(')','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#director name\n",
    "if2 = str(tabla[0]('a')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frank Darabont (dir.), Tim Robbins, Morgan Freeman'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk2 = if2.find('\">')\n",
    "mk1 = if2.find(\"title=\") +7\n",
    "sub = if2[mk1:mk2]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = []\n",
    "lst2 = []\n",
    "lst3 = []\n",
    "for i in range(1,501,2):\n",
    "    lst1.append(tabla[0](\"a\")[i].text)\n",
    "for i in range (5,1755,7):\n",
    "    lst2.append(tabla[0](\"span\")[i].text.replace(\"(\",\"\").replace(\")\",\"\"))\n",
    "for i in range(1,501,2):\n",
    "    if2 = str(tabla[0](\"a\")[i])\n",
    "    mk2 = if2.find('\">')\n",
    "    mk1 = if2.find(\"title=\") +7\n",
    "    lst3.append(if2[mk1:mk2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cadena perpetua',\n",
       " 'El padrino',\n",
       " 'El caballero oscuro',\n",
       " 'El padrino (parte II)',\n",
       " '12 hombres sin piedad',\n",
       " 'La lista de Schindler',\n",
       " 'El señor de los anillos: El retorno del rey',\n",
       " 'Pulp Fiction',\n",
       " 'El señor de los anillos: La comunidad del anillo',\n",
       " 'El bueno, el feo y el malo']"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1994',\n",
       " '1972',\n",
       " '2008',\n",
       " '1974',\n",
       " '1957',\n",
       " '1993',\n",
       " '2003',\n",
       " '1994',\n",
       " '2001',\n",
       " '1966']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Frank Darabont (dir.), Tim Robbins, Morgan Freeman',\n",
       " 'Francis Ford Coppola (dir.), Marlon Brando, Al Pacino',\n",
       " 'Christopher Nolan (dir.), Christian Bale, Heath Ledger',\n",
       " 'Francis Ford Coppola (dir.), Al Pacino, Robert De Niro',\n",
       " 'Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb',\n",
       " 'Steven Spielberg (dir.), Liam Neeson, Ralph Fiennes',\n",
       " 'Peter Jackson (dir.), Elijah Wood, Viggo Mortensen',\n",
       " 'Quentin Tarantino (dir.), John Travolta, Uma Thurman',\n",
       " 'Peter Jackson (dir.), Elijah Wood, Ian McKellen',\n",
       " 'Sergio Leone (dir.), Clint Eastwood, Eli Wallach']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst3[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['movie_name']= lst1\n",
    "df['initial_release']=lst2\n",
    "df['director_name_stars']=lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_name</th>\n",
       "      <th>initial_release</th>\n",
       "      <th>director_name_stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cadena perpetua</td>\n",
       "      <td>1994</td>\n",
       "      <td>Frank Darabont (dir.), Tim Robbins, Morgan Fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El padrino</td>\n",
       "      <td>1972</td>\n",
       "      <td>Francis Ford Coppola (dir.), Marlon Brando, Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El caballero oscuro</td>\n",
       "      <td>2008</td>\n",
       "      <td>Christopher Nolan (dir.), Christian Bale, Heat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El padrino (parte II)</td>\n",
       "      <td>1974</td>\n",
       "      <td>Francis Ford Coppola (dir.), Al Pacino, Robert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 hombres sin piedad</td>\n",
       "      <td>1957</td>\n",
       "      <td>Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              movie_name initial_release  \\\n",
       "0        Cadena perpetua            1994   \n",
       "1             El padrino            1972   \n",
       "2    El caballero oscuro            2008   \n",
       "3  El padrino (parte II)            1974   \n",
       "4  12 hombres sin piedad            1957   \n",
       "\n",
       "                                 director_name_stars  \n",
       "0  Frank Darabont (dir.), Tim Robbins, Morgan Fre...  \n",
       "1  Francis Ford Coppola (dir.), Marlon Brando, Al...  \n",
       "2  Christopher Nolan (dir.), Christian Bale, Heat...  \n",
       "3  Francis Ford Coppola (dir.), Al Pacino, Robert...  \n",
       "4      Sidney Lumet (dir.), Henry Fonda, Lee J. Cobb  "
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the city:d\n"
     ]
    }
   ],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n",
    "# usamos requests para extraer el html en string\n",
    "\n",
    "html=req.get(url).text\n",
    "\n",
    "# parsear\n",
    "\n",
    "soup=bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla = soup.find_all('li', class_ = 'col-xs-6 col-sm-4 col-md-3 col-lg-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#name\n",
    "if2 = str(tabla[0]('a')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tipping the Velvet'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mk2 = if2.find('\">')\n",
    "mk1 = if2.find(\"title=\") +7\n",
    "sub = if2[mk1:mk2]\n",
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'£51.77'"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#price\n",
    "tabla[0]('p')[1].text.replace('Â', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In stock'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stock\n",
    "tabla[0]('p')[2].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = []\n",
    "lst2 = []\n",
    "lst3 = []\n",
    "for i in range(len(tabla)):\n",
    "    if2 = str(tabla[i]('a')[1])\n",
    "    mk2 = if2.find('\">')\n",
    "    mk1 = if2.find(\"title=\") +7\n",
    "    lst1.append(if2[mk1:mk2])\n",
    "for i in range(len(tabla)):\n",
    "    lst2.append(tabla[i]('p')[1].text.replace('Â', ''))\n",
    "for i in range(len(tabla)):\n",
    "    lst3.append(tabla[i]('p')[2].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_name']= lst1\n",
    "df['price']=lst2\n",
    "df['stock_availability']=lst3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_name</th>\n",
       "      <th>price</th>\n",
       "      <th>stock_availability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Light in the Attic</td>\n",
       "      <td>£51.77</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tipping the Velvet</td>\n",
       "      <td>£53.74</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Soumission</td>\n",
       "      <td>£50.10</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>£47.82</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sapiens: A Brief History of Humankind</td>\n",
       "      <td>£54.23</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Requiem Red</td>\n",
       "      <td>£22.65</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n",
       "      <td>£33.34</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Coming Woman: A Novel Based on the Life of...</td>\n",
       "      <td>£17.93</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Boys in the Boat: Nine Americans and Their...</td>\n",
       "      <td>£22.60</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Black Maria</td>\n",
       "      <td>£52.15</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n",
       "      <td>£13.99</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Shakespeare's Sonnets</td>\n",
       "      <td>£20.66</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Set Me Free</td>\n",
       "      <td>£17.46</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n",
       "      <td>£52.29</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rip it Up and Start Again</td>\n",
       "      <td>£35.02</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n",
       "      <td>£57.25</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Olio</td>\n",
       "      <td>£23.88</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n",
       "      <td>£37.59</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Libertarianism for Beginners</td>\n",
       "      <td>£51.33</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>It's Only the Himalayas</td>\n",
       "      <td>£45.17</td>\n",
       "      <td>In stock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            book_name   price  \\\n",
       "0                                A Light in the Attic  £51.77   \n",
       "1                                  Tipping the Velvet  £53.74   \n",
       "2                                          Soumission  £50.10   \n",
       "3                                       Sharp Objects  £47.82   \n",
       "4               Sapiens: A Brief History of Humankind  £54.23   \n",
       "5                                     The Requiem Red  £22.65   \n",
       "6   The Dirty Little Secrets of Getting Your Dream...  £33.34   \n",
       "7   The Coming Woman: A Novel Based on the Life of...  £17.93   \n",
       "8   The Boys in the Boat: Nine Americans and Their...  £22.60   \n",
       "9                                     The Black Maria  £52.15   \n",
       "10     Starving Hearts (Triangular Trade Trilogy, #1)  £13.99   \n",
       "11                              Shakespeare's Sonnets  £20.66   \n",
       "12                                        Set Me Free  £17.46   \n",
       "13  Scott Pilgrim's Precious Little Life (Scott Pi...  £52.29   \n",
       "14                          Rip it Up and Start Again  £35.02   \n",
       "15  Our Band Could Be Your Life: Scenes from the A...  £57.25   \n",
       "16                                               Olio  £23.88   \n",
       "17  Mesaerion: The Best Science Fiction Stories 18...  £37.59   \n",
       "18                       Libertarianism for Beginners  £51.33   \n",
       "19                            It's Only the Himalayas  £45.17   \n",
       "\n",
       "   stock_availability  \n",
       "0            In stock  \n",
       "1            In stock  \n",
       "2            In stock  \n",
       "3            In stock  \n",
       "4            In stock  \n",
       "5            In stock  \n",
       "6            In stock  \n",
       "7            In stock  \n",
       "8            In stock  \n",
       "9            In stock  \n",
       "10           In stock  \n",
       "11           In stock  \n",
       "12           In stock  \n",
       "13           In stock  \n",
       "14           In stock  \n",
       "15           In stock  \n",
       "16           In stock  \n",
       "17           In stock  \n",
       "18           In stock  \n",
       "19           In stock  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
